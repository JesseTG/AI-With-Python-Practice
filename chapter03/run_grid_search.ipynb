{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "Each model is given parameters in the constructor.  We could try to tune them ourselves, but there are many possible combinations.  Checking every possible combination isn't practical, so we use grid search.  We issue possible ranges of values for each parameter, then the grid search tries them out to maximise the effectiveness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from common import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = numpy.loadtxt(\"data_random_forests.txt\", delimiter=\",\")\n",
    "\n",
    "# X: 2D coordinates\n",
    "# Y: The integers 0, 1, or 2\n",
    "X, Y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# The data set, grouped by class\n",
    "classes = (X[Y == 0], X[Y == 1], X[Y == 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = model_selection.train_test_split(X, Y, test_size=0.25, random_state=5)\n",
    "\n",
    "feature_train, feature_test = split[0], split[1]\n",
    "class_train, class_test = split[2], split[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Parameter Grid\n",
    "\n",
    "In practice, we usually fix one parameter and vary others.  There's usually a metric or two that we want to maximize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\": [25, 50, 100, 250],\n",
    "    \"max_depth\": [2, 4, 7, 12, 16]\n",
    "}\n",
    "\n",
    "# The metrics we want to maximize\n",
    "metrics = ['precision_weighted', 'recall_weighted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_weighted:\n",
      "\tParams: {'max_depth': 2, 'n_estimators': 25}\t--> 0.83814\n",
      "\tParams: {'max_depth': 2, 'n_estimators': 50}\t--> 0.84481\n",
      "\tParams: {'max_depth': 2, 'n_estimators': 100}\t--> 0.84684\n",
      "\tParams: {'max_depth': 2, 'n_estimators': 250}\t--> 0.84806\n",
      "\tParams: {'max_depth': 4, 'n_estimators': 25}\t--> 0.84605\n",
      "\tParams: {'max_depth': 4, 'n_estimators': 50}\t--> 0.84002\n",
      "\tParams: {'max_depth': 4, 'n_estimators': 100}\t--> 0.84130\n",
      "\tParams: {'max_depth': 4, 'n_estimators': 250}\t--> 0.84486\n",
      "\tParams: {'max_depth': 7, 'n_estimators': 25}\t--> 0.84291\n",
      "\tParams: {'max_depth': 7, 'n_estimators': 50}\t--> 0.84058\n",
      "\tParams: {'max_depth': 7, 'n_estimators': 100}\t--> 0.84397\n",
      "\tParams: {'max_depth': 7, 'n_estimators': 250}\t--> 0.84847 (BEST)\n",
      "\tParams: {'max_depth': 12, 'n_estimators': 25}\t--> 0.83151\n",
      "\tParams: {'max_depth': 12, 'n_estimators': 50}\t--> 0.82906\n",
      "\tParams: {'max_depth': 12, 'n_estimators': 100}\t--> 0.83634\n",
      "\tParams: {'max_depth': 12, 'n_estimators': 250}\t--> 0.82754\n",
      "\tParams: {'max_depth': 16, 'n_estimators': 25}\t--> 0.81510\n",
      "\tParams: {'max_depth': 16, 'n_estimators': 50}\t--> 0.81659\n",
      "\tParams: {'max_depth': 16, 'n_estimators': 100}\t--> 0.81838\n",
      "\tParams: {'max_depth': 16, 'n_estimators': 250}\t--> 0.81707\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.85      0.88        79\n",
      "        1.0       0.84      0.83      0.83        70\n",
      "        2.0       0.85      0.92      0.89        76\n",
      "\n",
      "avg / total       0.87      0.87      0.87       225\n",
      "\n",
      "recall_weighted:\n",
      "\tParams: {'max_depth': 2, 'n_estimators': 25}\t--> 0.83259\n",
      "\tParams: {'max_depth': 2, 'n_estimators': 50}\t--> 0.83704\n",
      "\tParams: {'max_depth': 2, 'n_estimators': 100}\t--> 0.84000\n",
      "\tParams: {'max_depth': 2, 'n_estimators': 250}\t--> 0.84296\n",
      "\tParams: {'max_depth': 4, 'n_estimators': 25}\t--> 0.84296\n",
      "\tParams: {'max_depth': 4, 'n_estimators': 50}\t--> 0.83556\n",
      "\tParams: {'max_depth': 4, 'n_estimators': 100}\t--> 0.83704\n",
      "\tParams: {'max_depth': 4, 'n_estimators': 250}\t--> 0.84148\n",
      "\tParams: {'max_depth': 7, 'n_estimators': 25}\t--> 0.84000\n",
      "\tParams: {'max_depth': 7, 'n_estimators': 50}\t--> 0.83704\n",
      "\tParams: {'max_depth': 7, 'n_estimators': 100}\t--> 0.84148\n",
      "\tParams: {'max_depth': 7, 'n_estimators': 250}\t--> 0.84593 (BEST)\n",
      "\tParams: {'max_depth': 12, 'n_estimators': 25}\t--> 0.82963\n",
      "\tParams: {'max_depth': 12, 'n_estimators': 50}\t--> 0.82667\n",
      "\tParams: {'max_depth': 12, 'n_estimators': 100}\t--> 0.83407\n",
      "\tParams: {'max_depth': 12, 'n_estimators': 250}\t--> 0.82519\n",
      "\tParams: {'max_depth': 16, 'n_estimators': 25}\t--> 0.81333\n",
      "\tParams: {'max_depth': 16, 'n_estimators': 50}\t--> 0.81481\n",
      "\tParams: {'max_depth': 16, 'n_estimators': 100}\t--> 0.81630\n",
      "\tParams: {'max_depth': 16, 'n_estimators': 250}\t--> 0.81481\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.85      0.88        79\n",
      "        1.0       0.84      0.83      0.83        70\n",
      "        2.0       0.85      0.92      0.89        76\n",
      "\n",
      "avg / total       0.87      0.87      0.87       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    print(\"{0}:\".format(metric))\n",
    "    extreme_forest = ExtraTreesClassifier(random_state=0)\n",
    "    classifier = model_selection.GridSearchCV(extreme_forest, parameters, cv=5, scoring=metric, n_jobs=-1)\n",
    "    classifier.fit(feature_train, class_train)\n",
    "    \n",
    "    best = lambda b: \" (BEST)\" if b == classifier.best_params_ else \"\" \n",
    "\n",
    "    for params, average, _ in classifier.grid_scores_:\n",
    "        print(\"\\tParams: {0}\\t--> {1:.5f}{2}\".format(params, average, best(params)))\n",
    "\n",
    "    predictions = classifier.predict(feature_test)\n",
    "    \n",
    "    print()\n",
    "    print(classification_report(class_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
